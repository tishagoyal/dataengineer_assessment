# dataengineer_assessment

This program initially reads the text file and cleans the data by removing all the white spaces and extra characters
Then we tokenize each data line by spliting it using delimeter "|"
Each token is then placed into its respective Column of the dataframe df.
